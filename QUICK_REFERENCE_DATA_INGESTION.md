# Data Ingestion - Quick Reference Card

## üöÄ Quick Setup (5 Minutes)

```bash
# 1. Install dependencies
pip install schedule psycopg2-binary cryptography

# 2. Generate encryption key
python scripts/setup_data_ingestion.py

# 3. Run migration
alembic revision --autogenerate -m "Add external data sources"
alembic upgrade head

# 4. Start server
uvicorn backend.main:app --reload
```

## üìã Common Commands

### Register Data Source (Database Storage)
```bash
curl -X POST http://localhost:8000/data-sources/create \
  -H "Content-Type: application/json" \
  -d '{
    "name": "MoE_DB",
    "ministry_name": "Ministry of Education",
    "host": "db.example.com",
    "port": 5432,
    "database_name": "docs",
    "username": "readonly",
    "password": "pass123",
    "table_name": "documents",
    "file_column": "file_data",
    "filename_column": "filename",
    "storage_type": "database"
  }'
```

### Register Data Source (Supabase Storage)
```bash
curl -X POST http://localhost:8000/data-sources/create \
  -H "Content-Type: application/json" \
  -d '{
    "name": "MoE_Supabase",
    "ministry_name": "Ministry of Education",
    "host": "db.example.com",
    "port": 5432,
    "database_name": "docs",
    "username": "readonly",
    "password": "pass123",
    "table_name": "documents",
    "file_column": "file_path",
    "filename_column": "filename",
    "storage_type": "supabase",
    "supabase_url": "https://your-project.supabase.co",
    "supabase_key": "your-supabase-key",
    "supabase_bucket": "ministry-docs",
    "file_path_prefix": "resume/"
  }'
```

### Test Connection
```bash
curl -X POST http://localhost:8000/data-sources/test-connection \
  -H "Content-Type: application/json" \
  -d '{
    "host": "db.example.com",
    "port": 5432,
    "database_name": "docs",
    "username": "readonly",
    "password": "pass123"
  }'
```

### List Sources
```bash
curl http://localhost:8000/data-sources/list
```

### Trigger Sync
```bash
# Specific source
curl -X POST http://localhost:8000/data-sources/1/sync

# All sources
curl -X POST http://localhost:8000/data-sources/sync-all

# With limit
curl -X POST "http://localhost:8000/data-sources/1/sync?limit=10"
```

### Check Logs
```bash
# Specific source
curl http://localhost:8000/data-sources/1/sync-logs

# All sources
curl http://localhost:8000/data-sources/sync-logs/all
```

### Update Source
```bash
curl -X PUT http://localhost:8000/data-sources/1 \
  -H "Content-Type: application/json" \
  -d '{"sync_enabled": false}'
```

### Delete Source
```bash
curl -X DELETE http://localhost:8000/data-sources/1
```

## üêç Python Examples

### Register & Sync
```python
import requests

# Register
response = requests.post("http://localhost:8000/data-sources/create", json={
    "name": "MoE_DB",
    "ministry_name": "Ministry of Education",
    "host": "db.example.com",
    "port": 5432,
    "database_name": "docs",
    "username": "readonly",
    "password": "pass123",
    "table_name": "documents",
    "file_column": "file_data",
    "filename_column": "filename"
})

source_id = response.json()["source_id"]

# Sync
requests.post(f"http://localhost:8000/data-sources/{source_id}/sync")

# Check logs
logs = requests.get(f"http://localhost:8000/data-sources/{source_id}/sync-logs")
print(logs.json())
```

### Query Synced Documents
```python
# Query via RAG
response = requests.post("http://localhost:8000/chat/query", json={
    "question": "What are the latest policies?",
    "thread_id": "session_1"
})

print(response.json()["answer"])
```

## üóÑÔ∏è Database Table Structure

### External Database Requirements
```sql
-- Your external ministry database should have:
CREATE TABLE documents (
    id SERIAL PRIMARY KEY,
    filename VARCHAR(255),           -- Required
    file_data BYTEA,                 -- Required (or file_path)
    department VARCHAR(100),         -- Optional metadata
    created_at TIMESTAMP             -- Optional
);
```

## üîê Environment Variables

Add to `.env`:
```env
# Generated by setup script
DB_ENCRYPTION_KEY=your_generated_key_here
```

## üìä API Response Examples

### Successful Sync
```json
{
  "status": "sync_started",
  "source_id": 1,
  "source_name": "MoE_DB",
  "message": "Sync started in background"
}
```

### Sync Logs
```json
{
  "source_id": 1,
  "total_logs": 1,
  "logs": [{
    "status": "success",
    "documents_fetched": 25,
    "documents_processed": 25,
    "documents_failed": 0,
    "sync_duration_seconds": 45,
    "started_at": "2025-11-28T10:30:00"
  }]
}
```

### Connection Test
```json
{
  "status": "success",
  "message": "Connection successful"
}
```

## üîß Configuration

### Change Sync Time
Edit `backend/main.py`:
```python
start_scheduler(sync_time="03:00")  # 3 AM
```

### Supported File Types
- ‚úÖ PDF (.pdf)
- ‚úÖ Word (.docx)
- ‚úÖ Images (.jpg, .jpeg, .png) with OCR

## üêõ Troubleshooting

### Connection Fails
```bash
# Test connection first
curl -X POST http://localhost:8000/data-sources/test-connection ...

# Check PostgreSQL
psql -h HOST -U USER -d DATABASE
```

### Sync Fails
```bash
# Check logs
curl http://localhost:8000/data-sources/1/sync-logs

# Check server logs
tail -f Agent/agent_logs/pipeline.log
```

### Documents Not Appearing
```bash
# List documents
curl http://localhost:8000/documents/list

# Check if text extracted
curl http://localhost:8000/documents/123
```

## üìÅ File Locations

```
Agent/data_ingestion/          # Core module
backend/routers/data_source_router.py  # API endpoints
scripts/setup_data_ingestion.py        # Setup script
scripts/example_data_source_setup.py   # Example usage
tests/test_data_ingestion.py           # Tests
```

## üìö Documentation

- **Complete Guide**: DATA_INGESTION_GUIDE.md
- **Implementation**: DATA_INGESTION_IMPLEMENTATION.md
- **Module README**: Agent/data_ingestion/README.md
- **API Docs**: http://localhost:8000/docs

## ‚ö° Quick Test

```bash
# 1. Setup
python scripts/setup_data_ingestion.py
alembic upgrade head

# 2. Start server
uvicorn backend.main:app --reload

# 3. Run example
python scripts/example_data_source_setup.py

# 4. Check API docs
open http://localhost:8000/docs
```

## üéØ Workflow

```
Register ‚Üí Test ‚Üí Sync ‚Üí Monitor ‚Üí Query
   ‚Üì        ‚Üì      ‚Üì       ‚Üì        ‚Üì
 /create  /test  /sync  /logs   /chat/query
```

## üí° Best Practices

1. ‚úÖ Test connection before registering
2. ‚úÖ Use read-only database users
3. ‚úÖ Start with small sync limits
4. ‚úÖ Monitor sync logs regularly
5. ‚úÖ Backup encryption key
6. ‚úÖ Schedule syncs off-peak hours

## üîó Related Endpoints

### Existing Endpoints (Still Work)
- `POST /documents/upload` - Manual upload
- `GET /documents/list` - List all docs
- `POST /chat/query` - Query RAG agent

### New Endpoints
- `POST /data-sources/create` - Register source
- `POST /data-sources/{id}/sync` - Trigger sync
- `GET /data-sources/sync-logs/all` - View logs

---

**Need Help?** Check DATA_INGESTION_GUIDE.md for detailed instructions
